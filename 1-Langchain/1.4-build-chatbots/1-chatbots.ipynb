{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() ## load env variable\n",
    "\n",
    "groq_api_key = os.getenv(\"GROG_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Hai! 👋\\n\\nIt's nice to meet you. What can I do for you today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 15, 'total_tokens': 42, 'completion_time': 0.049090909, 'prompt_time': 8.14e-05, 'queue_time': 0.015617250000000001, 'total_time': 0.049172309}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-39023a3d-76c3-4b83-9400-975ebda035ec-0', usage_metadata={'input_tokens': 15, 'output_tokens': 27, 'total_tokens': 42})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Hai\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Hai and that you are a Software Engineer!  \\n\\nIs there anything else you'd like to talk about? 😄  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 58, 'total_tokens': 93, 'completion_time': 0.063636364, 'prompt_time': 0.001842193, 'queue_time': 0.011584984999999999, 'total_time': 0.065478557}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-478165c8-752c-4e25-9328-325ade947790-0', usage_metadata={'input_tokens': 58, 'output_tokens': 35, 'total_tokens': 93})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Hai and I am a Software Engineer\"),\n",
    "        AIMessage(content=\"Hello Hai! It's nice to meet you. What can I do for you today\"),\n",
    "        HumanMessage(content=\"Hey Whats my name and What I do to\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Hai and I am a Software Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Hai, it's nice to meet you!\\n\\nAs a Software Engineer, what kind of projects are you working on these days?  \\n\\nI'm always interested in learning more about the work people do in the tech industry.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Hai.  \\n\\nI remember that you introduced yourself at the beginning of our conversation. 😊  \\n\\n\\nLet me know if you have any other questions!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 84, 'total_tokens': 120, 'completion_time': 0.065454545, 'prompt_time': 0.003233217, 'queue_time': 0.011161143, 'total_time': 0.068687762}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-704ca305-d18d-49de-bb2f-dbf0571af556-0', usage_metadata={'input_tokens': 84, 'output_tokens': 36, 'total_tokens': 120})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! 😊\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Change the config --> session id\n",
    "config1 = {\"configurable\" : {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, My name is Hai and I am a Software Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Hai, it's nice to meet you!\\n\\nAs a Software Engineer, what kind of projects are you working on these days?  \\n\\nI'm always interested in learning more about the work people do in the tech industry.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 21, 'total_tokens': 72, 'completion_time': 0.092727273, 'prompt_time': 0.000146779, 'queue_time': 0.014175791, 'total_time': 0.092874052}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2cb048a9-2a18-445f-b0e7-1d44119e7402-0', usage_metadata={'input_tokens': 21, 'output_tokens': 51, 'total_tokens': 72}), HumanMessage(content='What my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Hai.  \\n\\nI remember that you introduced yourself at the beginning of our conversation. 😊  \\n\\n\\nLet me know if you have any other questions!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 84, 'total_tokens': 120, 'completion_time': 0.065454545, 'prompt_time': 0.003233217, 'queue_time': 0.011161143, 'total_time': 0.068687762}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-704ca305-d18d-49de-bb2f-dbf0571af556-0', usage_metadata={'input_tokens': 84, 'output_tokens': 36, 'total_tokens': 120})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='What my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 13, 'total_tokens': 53, 'completion_time': 0.072727273, 'prompt_time': 8.5e-05, 'queue_time': 0.01429829, 'total_time': 0.072812273}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-490d3e54-708b-4940-81bb-7c754d1da5ee-0', usage_metadata={'input_tokens': 13, 'output_tokens': 40, 'total_tokens': 53})])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Hai, it's nice to meet you! 👋 \\n\\nHow can I help you today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 19, 'total_tokens': 46, 'completion_time': 0.049090909, 'prompt_time': 8.193e-05, 'queue_time': 0.013714450000000001, 'total_time': 0.049172839}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-584f5200-2144-4544-a725-ae2594741795-0', usage_metadata={'input_tokens': 19, 'output_tokens': 27, 'total_tokens': 46})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Hai\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Hai, it's nice to meet you! 👋  What can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 14, 'total_tokens': 38, 'completion_time': 0.043636364, 'prompt_time': 9.3339e-05, 'queue_time': 0.014649529, 'total_time': 0.043729703}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c3fd452a-d0f7-4c23-ab56-c24931d0280b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 24, 'total_tokens': 38})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\" : {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Hai\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are helpful assistant. Answer all question to the best of your ability in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xin chào Hai! Rất vui được gặp bạn. \\n\\nBạn có muốn hỏi tôi điều gì không? Tôi sẽ cố gắng hết sức để trả lời bạn một cách đầy đủ và chính xác nhất. \\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hi my name is Hai\")], \"language\": \"Vietnamese\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xin chào Hải! \\n\\nRất vui được gặp bạn. 😊  \\n\\nBạn muốn hỏi tôi điều gì không? \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\" : {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, I am Hai\")], \"language\": \"Vietnamese\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, can you help me with AI?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Of course! What would you like help with?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I need help with understanding about GenAI.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hello, can you help me with AI?\"),\n",
    "    AIMessage(content=\"Of course! What would you like help with?\"),\n",
    "    HumanMessage(content=\"I need help with understanding about GenAI.\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bạn muốn tìm hiểu về GenAI. \\n\\n(You asked about understanding GenAI.) \\n\\n\\nIs there anything specific about GenAI that you'd like to know? For example, are you curious about:\\n\\n* **What GenAI is?**\\n* **How it works?**\\n* **Its applications?**\\n* **The ethical implications?**\\n\\n\\n\\nI'm here to help you understand! Just let me know what you're most interested in. 😊\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is question I asked\")],\n",
    "        \"language\": \"Vietnamese\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap in Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config = {\"configurable\" : {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bạn cần giúp đỡ về việc hiểu GenAI. \\n\\n\\nYou asked: \"I need help with understanding about GenAI.\"\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is question I asked\")],\n",
    "        \"language\": \"Vietnamese\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
